{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00665454]\n",
      " [0.99246888]\n",
      " [0.99246917]\n",
      " [0.00701963]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def Sigmoid(z):\n",
    "    return 1/(1+np.exp(-z)) #Definición función sigma\n",
    "\n",
    "Sigmoid = np.vectorize(Sigmoid) #Vectorización función sigma para trabajar con arreglos\n",
    "\n",
    "\n",
    "def Dsigmoid(z):\n",
    "    return (1/(1+np.exp(-z)))*(1-(1/(1+np.exp(-z))))  # Definición derivada de función sigma \n",
    "\n",
    "Dsigmoid = np.vectorize(Dsigmoid) #Vectorización derivada de función sigma para trabajar con arreglos\n",
    "\n",
    "\n",
    "X=np.array([[0,0],[0,1],[1,0],[1,1]]) #Entrada\n",
    "Y=np.array([[0],[1],[1],[0]]) # Valores reales para y\n",
    "N=int(X.shape[0]) #Número de datos\n",
    "ncapas=2 #Numero de capas\n",
    "neucapa0 = int(X.shape[-1]) #Numero características\n",
    "neucapa1 = 2 #Numero de neuronas capa 1\n",
    "neucapa2 = 1 #Numero de neuronas capa 2\n",
    "neurona=[neucapa0,neucapa1,neucapa2] #Aregglo para almacenar numero de neuronas por capa\n",
    "alpha=10 #Hiperparámetro del SGD (lo puse en 10 pues en valores mas bajos se me atascaba en 0.5)\n",
    "\n",
    "\n",
    "\n",
    "A=[0,] #Arreglo para almacenar pesos\n",
    "B=[0,] #Arreglo para almacenar interceptos\n",
    "Z=[0,] #Arreglo para almacenar predcciones sin función de activación\n",
    "Xi=[X,] #Arreglo para almacenar predcciones sin función de activación\n",
    "\n",
    "\n",
    "#Inicialización\n",
    "for i in range (1,ncapas+1): \n",
    "\tA.append(np.random.uniform(-1,1,(int(neurona[i-1]),int(neurona[i]))))\n",
    "\tB.append(np.random.uniform(-1,1,(1,int(neurona[i]))))\n",
    "\tZ.append(np.dot(Xi[i-1],A[i]) + B[i])\n",
    "\tXi.append(Sigmoid(Z[i]))\n",
    "\t\n",
    "    \n",
    "deltaf= 2*(Xi[-1]-Y)/N\n",
    "delta=[0,deltaf,]\n",
    "Delta=[0,]\n",
    "GradA=[0,]\n",
    "GradB=[0,]\n",
    "\n",
    "\n",
    "for j in range(5000): #5000 épocas\n",
    "\n",
    "    \n",
    "\tfor k in range(1,ncapas+1): #Backpropagation\n",
    "    \n",
    "\t\tDelta.append(delta[k]*Dsigmoid(Z[-k]))\n",
    "\t\tGradA.append(np.dot(Xi[-(k+1)].T,Delta[k]))\n",
    "\t\tGradB.append(Delta[k].sum(axis=0))\n",
    "\t\tdelta.append(np.dot(Delta[k],A[-k].T))\n",
    "        \n",
    "\tfor l in range(1,ncapas+1): #Actualización pesos\n",
    "        \n",
    "\t\tA[l]= A[l] - alpha*GradA[-l]\n",
    "\t\tB[l]= B[l] - alpha*GradB[-l]\n",
    "    \n",
    "    \n",
    "\tZ=[0,]\n",
    "\tXi=[X,]\n",
    "    \n",
    "\tfor m in range (1,ncapas+1): #Inferencia\n",
    "        \n",
    "\t\tZ.append(np.dot(Xi[m-1],A[m]) + B[m])\n",
    "\t\tXi.append(Sigmoid(Z[m]))\n",
    "\t\n",
    "\tdeltaf= 2*(Xi[-1]-Y)/N\n",
    "\t\n",
    "\tdelta=[0,deltaf,]\n",
    "\tDelta=[0,]\n",
    "\tGradA=[0,]\n",
    "\tGradB=[0,]\n",
    "        \n",
    "            \n",
    "print(Xi[-1]) #Predicción\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
